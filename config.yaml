# Real-Time Multilingual ASR Configuration

project:
  name: "multilingual-asr"
  version: "1.0.0"
  seed: 42
  device: "cuda"  # cuda or cpu

data:
  sampling_rate: 16000
  chunk_size_sec: 2.0
  chunk_overlap_sec: 0.2
  audio_max_length_sec: 30.0
  vad_threshold: 0.5
  datasets:
    - name: "peoples_speech"
      version: "v1"
      split: "train+validation"
    - name: "common_voice"
      language: "en"
      version: "11.0"
      split: "train+validation"
    - name: "speechocean762"
      version: "v1"
  augmentation:
    enabled: false  # Disabled temporarily - causing NaN gradients
    speed_perturbation: [0.9, 1.0, 1.1]
    pitch_shift_semitones: [-2, 0, 2]
    background_noise_prob: 0.3

model:
  variants:
    tiny: "openai/whisper-tiny"
    base: "openai/whisper-base"
    small: "openai/whisper-small"
    medium: "openai/whisper-medium"
    distil: "distil-whisper/distil-large-v3"
  default_variant: "small"  # Using small for better quality with 80GB GPU
  language: "english"
  task: "transcribe"
  freeze_encoder: false
  freeze_layers: 0  # Can freeze first 2-4 layers to speed up training

training:
  batch_size: 8  # Reduced to improve stability
  gradient_accumulation_steps: 4  # Maintain effective batch size of 32
  num_epochs: 5  # Increased for better convergence with larger dataset
  learning_rate: 1.0e-5  # Much lower to prevent gradient explosion
  warmup_steps: 500  # Longer warmup for stability
  weight_decay: 0.01
  max_grad_norm: 5.0  # Increased to standard value - 0.5 was way too strict
  eval_steps: 50  # More frequent evaluation
  save_steps: 100  # Save checkpoints more frequently
  save_total_limit: 3  # Keep top 3 checkpoints
  early_stopping_patience: 3  # More patience for larger dataset
  fp16: true  # Keep mixed precision for efficiency

evaluation:
  metrics:
    - "wer"
    - "cer"
  test_sets:
    - "test_clean"
    - "test_accented"
  latency_benchmark_clips: 100

inference:
  streaming:
    enabled: true
    buffer_size_sec: 2.0
    overlap_sec: 0.2
    vad_enabled: true
  batch_size: 1
  num_beams: 1
  temperature: 0.0
  compression_ratio_threshold: 2.4
  logprob_threshold: -1.0
  no_speech_threshold: 0.6

mlops:
  experiment_tracking:
    backend: "wandb"  # wandb, mlflow, tensorboard
    project_name: "whisper-asr"
  versioning:
    data_version_file: "data_versions.txt"
    model_registry: "model_registry.json"
  logging:
    level: "INFO"
    save_logs: true
